# GymTrainer: AI-Powered Real-Time Exercise Analysis ğŸ‹ï¸â€â™‚ï¸ğŸ¤–

**Deep Learning Final Project (2026a) | HIT**
**Authors:** Amit Wagensberg & Ori Zarfaty

## ğŸ“Œ Overview
GymTrainer is a real-time computer vision application designed to act as a personal AI fitness trainer. It utilizes **MediaPipe Pose** for skeletal tracking and a custom **Long Short-Term Memory (LSTM)** neural network to recognize exercises and count repetitions with high accuracy.

Unlike simple geometric counters, GymTrainer uses deep learning to understand the *temporal dynamics* of movement, distinguishing between similar exercises (like Shoulder Press vs. Push-ups) and providing audio-visual feedback.

## ğŸ“‰ Baseline Comparison (Why Deep Learning?)
To validate our approach, we initially implemented a standard Machine Learning baseline using a **Decision Tree Classifier**.

* **The Experiment:** We trained a Decision Tree on the same geometric features without temporal context (treating each frame independently).
* **The Result:** The Decision Tree performed poorly struggling to distinguish between static holds and dynamic movements (e.g., identifying the difference between "holding a push-up position" and "doing a push-up").
* **Conclusion:** This failure confirmed that **Temporal Analysis** is critical. The LSTM model succeeded where the Decision Tree failed because it analyzes the *sequence* of 30 frames, allowing it to understand motion rather than just static poses.

## ğŸš€ Features
* **Real-Time Action Recognition:** Classifies 4 distinct exercises:
    * Squat
    * Push-up
    * Shoulder Press
    * Bicep Curl
* **Repetition Counting:** Uses geometric logic combined with AI classification to count valid reps.
* **Calorie Estimation:** Estimates calories burned per rep based on exercise type.
* **Audio Feedback:** TTS (Text-to-Speech) announces rep counts and sets.
* **Visual Feedback:** On-screen skeleton overlay, progress bars, and stability indicators.
* **Privacy First:** All processing is done locally on the CPU (no video sent to the cloud).

## ğŸ› ï¸ Architecture
The system operates on a 3-stage pipeline:

1.  **Data Acquisition:**
    * Input: Webcam video stream.
    * Tool: **MediaPipe Pose** extracts 33 3D skeletal landmarks.
2.  **Feature Engineering:**
    * Raw coordinates (x, y, z) are converted into **6 biomechanical joint angles**.
    * This makes the model invariant to camera distance and user height.
3.  **Classification (Deep Learning):**
    * **Model:** Custom LSTM (Recurrent Neural Network).
    * **Input:** A sliding window of **30 frames** (temporal sequence).
    * **Output:** Probability distribution across the 4 exercise classes.
  
    ## ğŸ“‚ Project Structure
```bash
GymTrainer/
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ gym_lstm_model.keras    # ğŸ† Final LSTM Model (Deep Learning)
â”‚   â””â”€â”€ gym_pose_classifier.pkl # ğŸ“‰ Baseline Decision Tree Model (Weights)
â”‚
â”œâ”€â”€ data_processing/
â”‚   â”œâ”€â”€ X_data.npy              # Processed features for LSTM
â”‚   â”œâ”€â”€ y_data.npy              # Processed labels for LSTM
â”‚   â””â”€â”€ classes.npy             # Class names (Squat, Push-up, etc.)
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ train_lstm.py           # Main script to train the LSTM model
â”‚   â”œâ”€â”€ preprocess.py           # Data extraction pipeline for LSTM
â”‚   â”œâ”€â”€ old_preprocess.txt      # training for Decision Tree Baseline
â”‚   â””â”€â”€ main.py                 # ğŸš€ Main Application (Webcam Inference)
â”‚
â””â”€â”€ README.md                   # Project Documentation
